{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"U9eCf8If4jXa","executionInfo":{"status":"ok","timestamp":1668935107531,"user_tz":-540,"elapsed":689,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/DataScience/PROJECT/2022_KGQA/paper\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5i88Rqfd4UDq","executionInfo":{"status":"ok","timestamp":1668935110983,"user_tz":-540,"elapsed":1419,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["import numpy as np\n","from tqdm.auto import tqdm\n","import torch\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","from dataloader import DatasetMetaQA, DataLoaderMetaQA\n","from model import RelationExtractor"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Ywirguqm3iaN","executionInfo":{"status":"ok","timestamp":1668935110984,"user_tz":-540,"elapsed":4,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["# {entity name: entity embedding} / {relation_name: relation_embedding} 으로 변환\n","def preprocess_entities_relations(entity_dict, relation_dict, entities, relations):\n","    e = {}\n","    r = {}\n","\n","    f = open(entity_dict, 'r')\n","    for line in f:\n","        line = line.strip().split('\\t')\n","        ent_id = int(line[0])\n","        ent_name = line[1]\n","        e[ent_name] = entities[ent_id]\n","    f.close()\n","\n","    f = open(relation_dict,'r')\n","    for line in f:\n","        line = line.strip().split('\\t')\n","        rel_id = int(line[0])\n","        rel_name = line[1]\n","        r[rel_name] = relations[rel_id]\n","    f.close()\n","    return e,r\n","\n","# {entity word: entity id} / {entity id: entity word} / [entity embeddings]\n","def prepare_embeddings(embedding_dict):\n","    entity2idx = {}\n","    idx2entity = {}\n","    i = 0\n","    embedding_matrix = []\n","    for key, entity in embedding_dict.items():\n","        entity2idx[key.strip()] = i\n","        idx2entity[i] = key.strip()\n","        i += 1\n","        embedding_matrix.append(entity)\n","    return entity2idx, idx2entity, embedding_matrix\n","\n","# {Question: Answer} 형태의 데이터를 [Head, Question, Answer] 형태의 데이터로 변환\n","# split=True 의 경우 하나의 question에 여러 개의 answer 가 있는 경우, 여러 개의 data로 나누어서 저장\n","def process_text_file(text_file, split=False):\n","    data_file = open(text_file, 'r')\n","    data_array = []\n","    for data_line in data_file.readlines():\n","        data_line = data_line.strip()\n","        if data_line == '':\n","            continue\n","        data_line = data_line.strip().split('\\t')\n","        question = data_line[0].split('[')\n","        question_1 = question[0]\n","        question_2 = question[1].split(']')\n","        head = question_2[0].strip()\n","        question_2 = question_2[1]\n","        question = question_1+'NE'+question_2\n","        ans = data_line[1].split('|')\n","        data_array.append([head, question.strip(), ans])\n","    if split==False:\n","        return data_array\n","    else:\n","        data = []\n","        for line in data_array:\n","            head = line[0]\n","            question = line[1]\n","            tails = line[2]\n","            for tail in tails:\n","                data.append([head, question, tail])\n","        return data\n","\n","# Head 와 Answer 을 제외한 Question 에 대한 word 들을 idx 로 변환 \n","# relation 을 표현하는 word 들을 정리하는 느낌?\n","# max_len 은 가장 긴 word 길이\n","def get_vocab(data):\n","    word_to_ix = {}\n","    maxLength = 0\n","    idx2word = {}\n","    for d in data:\n","            sent = d[1]\n","            for word in sent.split():\n","                if word not in word_to_ix:\n","                    idx2word[len(word_to_ix)] = word\n","                    word_to_ix[word] = len(word_to_ix)\n","                    \n","            length = len(sent.split())\n","            if length > maxLength:\n","                maxLength = length\n","\n","    return word_to_ix, idx2word, maxLength\n","\n","def data_generator(data, word2ix, entity2idx):\n","    for i in range(len(data)):\n","        data_sample = data[i]\n","        head = entity2idx[data_sample[0].strip()]\n","        question = data_sample[1].strip().split(' ')\n","        encoded_question = [word2ix[word.strip()] for word in question]\n","        if type(data_sample[2]) is str:\n","            ans = entity2idx[data_sample[2]]\n","        else:\n","            ans = [entity2idx[entity.strip()] for entity in list(data_sample[2])]\n","\n","        yield torch.tensor(head, dtype=torch.long),torch.tensor(encoded_question, dtype=torch.long) , ans, torch.tensor(len(encoded_question), dtype=torch.long), data_sample[1]\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xhY0ySRX21uQ","executionInfo":{"status":"ok","timestamp":1668935110984,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["def train(data_path, entity_path, relation_path, entity_dict, relation_dict, neg_batch_size, batch_size, shuffle, num_workers, nb_epochs, embedding_dim, hidden_dim, relation_dim, gpu, use_cuda,patience, freeze, validate_every, num_hops, lr, entdrop, reldrop, scoredrop, l3_reg, model_name, decay, ls, w_matrix, bn_list, valid_data_path=None):\n","    \n","    # entity & relation 을 embedding 값으로 변환 (embedding 은 pretrained model 이용)\n","    entities = np.load(entity_path)\n","    relations = np.load(relation_path)\n","    e,r = preprocess_entities_relations(entity_dict, relation_dict, entities, relations)\n","    entity2idx, idx2entity, embedding_matrix = prepare_embeddings(e)\n","\n","    # Question - Answer preprocessing\n","    data = process_text_file(data_path, split=False)\n","\n","    # relation word \n","    word2ix,idx2word, max_len = get_vocab(data)\n","    hops = str(num_hops)\n","\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    # dataset: entity2id matrix 를 이용해서 question ids, head id, answer ids 형태로 변환\n","    # answer ids 의 경우 answer 가 여러 개인 경우 해당 id들은 모두 1\n","    # data_loader: 각 batch 별로 max_len 계산 후 question ids, head id, tail onehot ids\n","    dataset = DatasetMetaQA(data=data, word2ix=word2ix, relations=r, entities=e, entity2idx=entity2idx)\n","    data_loader = DataLoaderMetaQA(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","\n","    model = RelationExtractor(embedding_dim=embedding_dim, hidden_dim=hidden_dim, vocab_size=len(word2ix), num_entities = len(idx2entity), relation_dim=relation_dim, pretrained_embeddings=embedding_matrix, freeze=freeze, device=device, entdrop = entdrop, reldrop = reldrop, scoredrop = scoredrop, l3_reg = l3_reg, model = model_name, ls = ls, w_matrix = w_matrix, bn_list=bn_list)\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    scheduler = ExponentialLR(optimizer, decay)\n","    optimizer.zero_grad()\n","    best_score = -float(\"inf\")\n","    best_model = model.state_dict()\n","    no_update = 0\n","    for epoch in range(nb_epochs):\n","\n","        # 매 validate_every epoch 마다 validation 진행\n","        phases = []\n","        for i in range(validate_every):\n","            phases.append('train')\n","        phases.append('valid')\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()\n","                if freeze == True:\n","                    # print('Freezing batch norm layers')\n","                    model.apply(set_bn_eval)\n","                loader = tqdm(data_loader, total=len(data_loader), unit=\"batches\")\n","                running_loss = 0\n","                for i_batch, a in enumerate(loader):\n","                    model.zero_grad()\n","                    question = a[0].to(device)\n","                    sent_len = a[1].to(device)\n","                    positive_head = a[2].to(device)\n","                    positive_tail = a[3].to(device)                    \n","\n","                    loss = model(sentence=question, p_head=positive_head, p_tail=positive_tail, question_len=sent_len)\n","                    loss.backward()\n","                    optimizer.step()\n","                    running_loss += loss.item()\n","                    loader.set_postfix(Loss=running_loss/((i_batch+1)*batch_size), Epoch=epoch)\n","                    loader.set_description('{}/{}'.format(epoch, nb_epochs))\n","                    loader.update()\n","                \n","                scheduler.step()\n","\n","            elif phase=='valid':\n","                model.eval()\n","                eps = 0.0001\n","                answers, score = validate(model=model, data_path= valid_data_path, word2idx= word2ix, entity2idx= entity2idx, device=device, model_name=model_name)\n","                if score > best_score + eps:\n","                    best_score = score\n","                    no_update = 0\n","                    best_model = model.state_dict()\n","                    print(hops + \" hop Validation accuracy increased from previous epoch\", score)\n","                    _, test_score = validate(model=model, data_path= test_data_path, word2idx= word2ix, entity2idx= entity2idx, device=device, model_name=model_name)\n","                    print('Test score for best valid so far:', test_score)\n","                    # writeToFile(answers, 'results_' + model_name + '_' + hops + '.txt')\n","                    suffix = ''\n","                    if freeze == True:\n","                        suffix = '_frozen'\n","                    checkpoint_path = 'checkpoints/MetaQA/'\n","                    checkpoint_file_name = checkpoint_path +model_name+ '_' + hops + suffix + \".pt\"\n","                    print('Saving checkpoint to ', checkpoint_file_name)\n","                    torch.save(model.state_dict(), checkpoint_file_name)\n","                elif (score < best_score + eps) and (no_update < patience):\n","                    no_update +=1\n","                    print(\"Validation accuracy decreases to %f from %f, %d more epoch to check\"%(score, best_score, patience-no_update))\n","                elif no_update == patience:\n","                    print(\"Model has exceed patience. Saving best model and exiting\")\n","                    torch.save(best_model, checkpoint_path+ \"best_score_model.pt\")\n","                    exit()\n","                if epoch == nb_epochs-1:\n","                    print(\"Final Epoch has reached. Stopping and saving model.\")\n","                    torch.save(best_model, checkpoint_path +\"best_score_model.pt\")\n","                    exit()\n","\n","def validate(data_path, device, model, word2idx, entity2idx, model_name):\n","    model.eval()\n","    data = process_text_file(data_path)\n","    answers = []\n","    data_gen = data_generator(data=data, word2ix=word2idx, entity2idx=entity2idx)\n","    total_correct = 0\n","    error_count = 0\n","    for i in tqdm(range(len(data))):\n","        try:\n","            d = next(data_gen)\n","            head = d[0].to(device)\n","            question = d[1].to(device)\n","            ans = d[2]\n","            ques_len = d[3].unsqueeze(0)\n","            tail_test = torch.tensor(ans, dtype=torch.long).to(device)\n","\n","            # (head-relation-tail) 중 score 가 가장 높은 top k개 추출\n","            top_2 = model.get_score_ranked(head=head, sentence=question, sent_len=ques_len)\n","            top_2_idx = top_2[1].tolist()[0]\n","            head_idx = head.tolist()\n","            if top_2_idx[0] == head_idx:\n","                pred_ans = top_2_idx[1]\n","            else:\n","                pred_ans = top_2_idx[0]\n","            if type(ans) is int:\n","                ans = [ans]\n","            is_correct = 0\n","            if pred_ans in ans:\n","                total_correct += 1\n","                is_correct = 1\n","\n","            # question + prediction + correctness 저장\n","            q_text = d[-1]\n","            answers.append(q_text + '\\t' + str(pred_ans) + '\\t' + str(is_correct))\n","        except:\n","            error_count += 1\n","            \n","    print(error_count)\n","    accuracy = total_correct/len(data)\n","    return answers, accuracy"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"65qCOpcu43SL","executionInfo":{"status":"ok","timestamp":1668935110984,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["hops = 2\n","model_name = 'ComplEx'\n","kg_type = 'half'\n","neg_batch_size = 128\n","batch_size = 128\n","shuffle_data = True\n","num_workers = 2\n","nb_epochs = 10\n","embedding_dim = 256\n","hidden_dim = 256\n","relation_dim = 200\n","gpu = 0\n","use_cuda = True\n","patience = 5\n","validate_every = 5\n","freeze = 0\n","lr = 0.0005\n","entdrop = 0.1\n","reldrop = 0.2\n","scoredrop = 0.2\n","l3_reg = 0.0\n","model = 'ComplEx'\n","decay = 1.0\n","ls = 0.0"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"aJW3fndH26pR","executionInfo":{"status":"ok","timestamp":1668935112328,"user_tz":-540,"elapsed":2,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["data_path = 'data/QA_data/MetaQA/qa_train_' + f\"{hops}hop\" + '.txt'\n","\n","hops_without_old = f\"{hops}hop\".replace('_old', '')\n","valid_data_path = 'data/QA_data/MetaQA/qa_dev_' + hops_without_old + '.txt'\n","test_data_path = 'data/QA_data/MetaQA/qa_test_' + hops_without_old + '.txt'\n","\n","embedding_folder = 'pretrained_models/embeddings/' + model_name + '_MetaQA_' + kg_type\n","entity_embedding_path = embedding_folder + '/E.npy'\n","relation_embedding_path = embedding_folder + '/R.npy'\n","entity_dict = embedding_folder + '/entities.dict'\n","relation_dict = embedding_folder + '/relations.dict'\n","w_matrix =  embedding_folder + '/W.npy'"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cX6sX3bP4R6e","executionInfo":{"status":"ok","timestamp":1668935115902,"user_tz":-540,"elapsed":2478,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"outputs":[],"source":["bn_list = []\n","\n","for i in range(3):\n","    bn = np.load(embedding_folder + '/bn' + str(i) + '.npy', allow_pickle=True)\n","    bn_list.append(bn.item())"]},{"cell_type":"markdown","source":["# test"],"metadata":{"id":"m2l15mdlAW4v"}},{"cell_type":"code","source":["entities = np.load(entity_embedding_path)\n","relations = np.load(relation_embedding_path)\n","e,r = preprocess_entities_relations(entity_dict, relation_dict, entities, relations)\n","entity2idx, idx2entity, embedding_matrix = prepare_embeddings(e)\n","\n","# Question - Answer preprocessing\n","data = process_text_file(data_path, split=False)\n","test_data = process_text_file(test_data_path, split=False)\n","\n","word2ix,idx2word, max_len = get_vocab(data)\n","hops = str(hops)"],"metadata":{"id":"GbriTTtg_-EG","executionInfo":{"status":"ok","timestamp":1668935128392,"user_tz":-540,"elapsed":5458,"user":{"displayName":"김유정","userId":"01965990861840034406"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = RelationExtractor(embedding_dim=embedding_dim, hidden_dim=hidden_dim, vocab_size=len(word2ix), num_entities = len(idx2entity), relation_dim=relation_dim, pretrained_embeddings=embedding_matrix, freeze=freeze, device=device, entdrop = entdrop, reldrop = reldrop, scoredrop = scoredrop, l3_reg = l3_reg, model = model_name, ls = ls, w_matrix = w_matrix, bn_list=bn_list)\n","model.to(device)\n","\n","model.load_state_dict(torch.load(\"checkpoints/MetaQA/best_score_model.pt\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KCl3_R5_mdT","executionInfo":{"status":"ok","timestamp":1668935141248,"user_tz":-540,"elapsed":10851,"user":{"displayName":"김유정","userId":"01965990861840034406"}},"outputId":"b5a65c92-829a-4db9-92a3-b4d726efce50"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model is ComplEx\n","Frozen: 0\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/DataScience/PROJECT/2022_KGQA/paper/model.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(pretrained_embeddings), freeze=self.freeze)\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"NehWSnu541V3","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["33da3c0f1d54497f80f9d9d1939c60be","2e5aababd20c4d77bba232285930cc5a","1a053ba6544c4f6694bb15964e34d763","9cff4e62007b4fcda9b8422b79ae5f0d","c211bdf472284268adfd7499e0f265a7","3d89594c608142d3975fdb775cfedff1","ba87da299d0941a59b1aee45e0f5a8c2","8d23f6b6d96842cbaa5663fbb87849b2","8b2f906321b846c1a3ecfa586d3950c7","e40ae0bdb1ef4106b1c7f80af84a5d80","e49cb33f5bbb4afdae68138a80201d94"]},"executionInfo":{"status":"ok","timestamp":1668935171184,"user_tz":-540,"elapsed":26867,"user":{"displayName":"김유정","userId":"01965990861840034406"}},"outputId":"ad834bf4-03fe-4b10-c951-c06ce0fd1790"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/14872 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33da3c0f1d54497f80f9d9d1939c60be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0\n"]}],"source":["test_pred, test_score = validate(model=model, data_path= test_data_path, word2idx= word2ix, entity2idx= entity2idx, device=device, model_name=model_name)\n","pred_ids = [i.split('\\t')[1] for i in test_pred]"]},{"cell_type":"code","source":["for i in range(5):\n","    print(f\"Head: {test_data[i][0]} / Qestion: {test_data[i][1]} / Pred: {idx2entity[int(pred_ids[i])]} / Answer: {test_data[i][2]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rq3nVwaBAolR","executionInfo":{"status":"ok","timestamp":1668935263477,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유정","userId":"01965990861840034406"}},"outputId":"4e1fe786-2e78-4477-ab55-c79aa3c146d2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Head: John Krasinski / Qestion: which person directed the movies starred by NE / Pred: Nancy Meyers / Answer: ['Nancy Meyers', 'Sam Mendes', 'George Clooney', 'Ken Kwapis', 'Luke Greenfield']\n","Head: Delbert Mann / Qestion: who are movie co-directors of NE / Pred: Cary Fukunaga / Answer: ['Franco Zeffirelli', 'Cary Fukunaga', 'Lewis Milestone', 'Robert Stevenson']\n","Head: David Mandel / Qestion: what are the primary languages in the movies directed by NE / Pred: German / Answer: ['German']\n","Head: Mimsy Farmer / Qestion: the screenwriter NE co-wrote movies with who / Pred: Barbet Schroeder / Answer: ['Barbet Schroeder']\n","Head: Shaun White / Qestion: the films acted by NE were in which genres / Pred: Documentary / Answer: ['Sport', 'Documentary']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6CwV4p92BXb7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1i8LXLeWmMOO8MOVwWNtqLo8TqAitovfs","authorship_tag":"ABX9TyNbMuekl//Qp/pQ/kltrvKl"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"33da3c0f1d54497f80f9d9d1939c60be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e5aababd20c4d77bba232285930cc5a","IPY_MODEL_1a053ba6544c4f6694bb15964e34d763","IPY_MODEL_9cff4e62007b4fcda9b8422b79ae5f0d"],"layout":"IPY_MODEL_c211bdf472284268adfd7499e0f265a7"}},"2e5aababd20c4d77bba232285930cc5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d89594c608142d3975fdb775cfedff1","placeholder":"​","style":"IPY_MODEL_ba87da299d0941a59b1aee45e0f5a8c2","value":"100%"}},"1a053ba6544c4f6694bb15964e34d763":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d23f6b6d96842cbaa5663fbb87849b2","max":14872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b2f906321b846c1a3ecfa586d3950c7","value":14872}},"9cff4e62007b4fcda9b8422b79ae5f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e40ae0bdb1ef4106b1c7f80af84a5d80","placeholder":"​","style":"IPY_MODEL_e49cb33f5bbb4afdae68138a80201d94","value":" 14872/14872 [00:26&lt;00:00, 587.57it/s]"}},"c211bdf472284268adfd7499e0f265a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d89594c608142d3975fdb775cfedff1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba87da299d0941a59b1aee45e0f5a8c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d23f6b6d96842cbaa5663fbb87849b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b2f906321b846c1a3ecfa586d3950c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e40ae0bdb1ef4106b1c7f80af84a5d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e49cb33f5bbb4afdae68138a80201d94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}